{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible features to implement:\n",
    "\n",
    "- Transaction History\n",
    "    - Amt, Timestamps -> Frequency\n",
    "- Current Balance\n",
    "- User interaction\n",
    "- Geolocation Data\n",
    "- Time patterns\n",
    "- How often users redeem rewards\n",
    "- Wallet features used\n",
    "- Financial Goals\n",
    "\n",
    "-Some attributes are categorical like user interaction. We might have to do some sort of engagement leveling for that.\n",
    "- Wallet features can indicate what kind of resources a user might desire:\n",
    "    - If they like to check their balance more than making transactions, it might be a sign that a user is considering making a purchase but is nervous about consequences regarding it. This could be \"scenario 1\" and can be encoded as a one hot vector like [1, 0, 0, ..., 0]\n",
    "\n",
    "### NOTE\n",
    "\n",
    "- Most features are tentative and may not be implemented. It is unclear as to what kind of data we will have access to at the current moment and whether or not hte collection of this data is feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data that I think should be collected:\n",
    "- X[:, 0] = Amt (transaction amount/price)\n",
    "- X[:, 1] = Timestamps (block timestamp)\n",
    "- X[:, 2] = User's current balance.\n",
    "- X[:, 3] = Age\n",
    "- X[:, 4] = Number of total transactions made\n",
    "- X[:, 5] = Knowledge index based off of tests and such\n",
    "\n",
    "Output:\n",
    "- If 0, then they're doing ok\n",
    "- If 1, then they may be a little reckless\n",
    "- If 2, then they may be very reckless\n",
    "- If 3, 100% reckless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ai/data/user-data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/littlerocket/Documents/AI and Blockchain/SupervisedCryptoWallet/F23_Supervised_Crypto_Wallet/ai/model.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/littlerocket/Documents/AI%20and%20Blockchain/SupervisedCryptoWallet/F23_Supervised_Crypto_Wallet/ai/model.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m DATAPATH \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./ai/data\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/littlerocket/Documents/AI%20and%20Blockchain/SupervisedCryptoWallet/F23_Supervised_Crypto_Wallet/ai/model.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Prototype read data function.\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/littlerocket/Documents/AI%20and%20Blockchain/SupervisedCryptoWallet/F23_Supervised_Crypto_Wallet/ai/model.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(DATAPATH \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/user-data.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, delimiter\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/littlerocket/Documents/AI%20and%20Blockchain/SupervisedCryptoWallet/F23_Supervised_Crypto_Wallet/ai/model.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df_out \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(DATAPATH \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/not-normalized.csv\u001b[39m\u001b[39m\"\u001b[39m, delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/littlerocket/Documents/AI%20and%20Blockchain/SupervisedCryptoWallet/F23_Supervised_Crypto_Wallet/ai/model.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Data matrix\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ai/data/user-data.csv'"
     ]
    }
   ],
   "source": [
    "# __dir__ = os.getcwd()\n",
    "DATAPATH = './ai/data'\n",
    "\n",
    "# Prototype read data function.\n",
    "df = pd.read_csv(DATAPATH + \"/user-data.csv\", delimiter=\",\")\n",
    "df_out = pd.read_csv(DATAPATH + \"/not-normalized.csv\", delimiter=\",\")\n",
    "\n",
    "# Data matrix\n",
    "D = df.to_numpy()\n",
    "Y = df_out.to_numpy()[:, -1]\n",
    "\n",
    "# Presumably, (# of points, 5)\n",
    "print(D.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "training_data, testing_data = np.column_stack((D[:80, :], Y[:80])), np.column_stack((D[80:, :], Y[80:]))\n",
    "\n",
    "training_data = training_data.astype(np.float64)\n",
    "testing_data = testing_data.astype(np.float64)  # or np.int32 depending on your requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is code heavily based on Zaki's implementation of a Simple Neural Network.\n",
    "\n",
    "# def relu(z):\n",
    "#     \"\"\"Apply the ReLU (Rectified Linear Unit) function.\"\"\"\n",
    "#     return np.maximum(0, z)\n",
    "\n",
    "# def relu_derivative(z):\n",
    "#     \"\"\"Compute the derivative of the ReLU function.\"\"\"\n",
    "#     return np.where(z > 0, 1, 0)\n",
    "\n",
    "# def feed_forward(x, network):\n",
    "#     \"\"\"Perform a feedforward pass through the neural network.\"\"\"\n",
    "#     activations = [x]\n",
    "#     input_to_layer = x\n",
    "\n",
    "#     for layer in network:\n",
    "#         z = layer['b'] + np.dot(layer['W'].T, input_to_layer)\n",
    "#         input_to_layer = relu(z)\n",
    "#         activations.append(input_to_layer)\n",
    "\n",
    "#     activations[-1] = softmax(activations[-1])\n",
    "#     return activations\n",
    "\n",
    "# def initialize_network(input_size, hidden_layer_sizes, output_size, scale):\n",
    "#     \"\"\"Initialize a deep multilayer perceptron with random weights and biases.\"\"\"\n",
    "#     layer_sizes = [input_size] + hidden_layer_sizes + [output_size]\n",
    "#     network = []\n",
    "\n",
    "#     for i in range(len(layer_sizes) - 1):\n",
    "#         layer = {\n",
    "#             'b': np.random.rand(layer_sizes[i + 1]) * scale,\n",
    "#             'W': np.random.rand(layer_sizes[i], layer_sizes[i + 1]) * scale\n",
    "#         }\n",
    "#         network.append(layer)\n",
    "\n",
    "#     return network\n",
    "\n",
    "# def deep_mlp_training(data, output_size, max_iter, learning_rate, hidden_layer_sizes, scale):\n",
    "#     \"\"\"Train a deep multilayer perceptron on the given dataset.\"\"\"\n",
    "#     num_samples, num_features = data.shape\n",
    "#     input_size = num_features - 1  # Last column is assumed to be the label\n",
    "#     network = initialize_network(input_size, hidden_layer_sizes, output_size, scale)\n",
    "\n",
    "#     for j in range(max_iter):\n",
    "#         indices = np.arange(num_samples)\n",
    "#         np.random.shuffle(indices)\n",
    "\n",
    "#         for i in indices:\n",
    "#             x_i = data[i, :-1]\n",
    "#             y_i = np.zeros(output_size)\n",
    "#             y_i[int(data[i, -1])] = 1\n",
    "\n",
    "#             # Forward pass\n",
    "#             activations = feed_forward(x_i, network)\n",
    "\n",
    "#             # Backpropagation\n",
    "#             deltas = [activations[-1] - y_i]\n",
    "#             for l in range(len(network) - 1, 0, -1):\n",
    "#                 delta = relu_derivative(np.dot(network[l]['W'], deltas[0]))\n",
    "#                 deltas.insert(0, delta)\n",
    "\n",
    "#             # Gradient descent parameter update\n",
    "#             for l, layer in enumerate(network):\n",
    "#                 layer['W'] -= learning_rate * np.outer(activations[l], deltas[l])\n",
    "#                 layer['b'] -= learning_rate * deltas[l]\n",
    "\n",
    "#     return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/littlerocket/Documents/AI and Blockchain/SupervisedCryptoWallet/F23_Supervised_Crypto_Wallet/ai/model.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/littlerocket/Documents/AI%20and%20Blockchain/SupervisedCryptoWallet/F23_Supervised_Crypto_Wallet/ai/model.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m best_params \u001b[39m=\u001b[39m cross_validation(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/littlerocket/Documents/AI%20and%20Blockchain/SupervisedCryptoWallet/F23_Supervised_Crypto_Wallet/ai/model.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                 training_data\u001b[39m=\u001b[39mtraining_data, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/littlerocket/Documents/AI%20and%20Blockchain/SupervisedCryptoWallet/F23_Supervised_Crypto_Wallet/ai/model.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                 input_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/littlerocket/Documents/AI%20and%20Blockchain/SupervisedCryptoWallet/F23_Supervised_Crypto_Wallet/ai/model.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                 output_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/littlerocket/Documents/AI%20and%20Blockchain/SupervisedCryptoWallet/F23_Supervised_Crypto_Wallet/ai/model.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m             )\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/littlerocket/Documents/AI%20and%20Blockchain/SupervisedCryptoWallet/F23_Supervised_Crypto_Wallet/ai/model.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(best_params)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_validation' is not defined"
     ]
    }
   ],
   "source": [
    "best_params = cross_validation(\n",
    "                training_data=training_data, \n",
    "                input_size=5,\n",
    "                output_size=4\n",
    "            )\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "optimal_hidden_layer_sizes = [best_params[0], 32]\n",
    "optimal_lr = best_params[1] \n",
    "\n",
    "# Train the model\n",
    "best_accuracy, model = run(\n",
    "    training_data=training_data[:,:-1],\n",
    "    test_data=testing_data[:,:-1],\n",
    "    Y_train=training_data[:,-1],\n",
    "    Y_test=testing_data[:,-1],\n",
    "    input_size=5,\n",
    "    hidden_layer_sizes=optimal_hidden_layer_sizes,\n",
    "    output_size=4,\n",
    "    epochs=1,  # Set your optimal number of epochs\n",
    "    batch_size=16,\n",
    "    eta=optimal_lr,\n",
    "    cuda=False,\n",
    "    num_rounds=200,\n",
    "    num_clients=8,\n",
    "    show_data=False\n",
    ")\n",
    "\n",
    "print(best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(optimal_hidden_layer_sizes, input_size=5, output_size=4):\n",
    "    # Initialize the model\n",
    "    model = DeepMLP(input_size, optimal_hidden_layer_sizes, output_size)\n",
    "\n",
    "    # Load the saved model parameters\n",
    "    model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
